SEARCH ENGINE DESIGN


Web crawler will parse a web page and add all of its links to a queue.
Do the same for each element on the queue.
Store each URL with the title in a database if it has not been visited:


---------------------------------------------------------
      ID      |      Title      |          URL          |
---------------------------------------------------------
   39839239         Google       https://www.google.com
   80293838         Amazon       https://www.amazon.ca
      ...             ...                 ...

(could be extended to contain more data)

Multiple instances of the crawler can run, each starting on a different page.


Create an API to return a list of pages from a query like such:

GET /api/search?q=Search%20Engine

response:

[
  {
        "title": "How Search Engines Work: Crawling, Indexing, and Ranking | Beginner&#039;s Guide to SEO - Moz",
        "url": "https://moz.com/beginners-guide-to-seo/how-search-engines-operate"
  },
  {
        "title": "Web search engine - Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Web_search_engine"
  }
]


Run Apache/Nginx (or write our own server ?) to serve a static page that has a search bar and a section for the results.
Perform API call using AJAX to get results based on the user's search query.
Update the results section with titles and links to relevant pages.

Put the project in a Docker image for easier deployment.
